# Donâ€™t load sample dags
AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
# Use the same folder used when mapping volume
AIRFLOW__CORE__DAGS_FOLDER=/usr/local/airflow/dags
# Setup access to postgresql backend
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgres+psycopg2://airflow:airflow@postgres:5432/airflow
# Used to secure variable in airflow backend
AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
# Use celery as a broker to distribute task
AIRFLOW__CORE__EXECUTOR=CeleryExecutor
# Key value backend for celery
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
# Postgresql backend for celery (not the same uri than for other connection)
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres:5432/airflow
# Metadata backend
AIRFLOW_CONN_METADATA_DB=postgres+psycopg2://airflow:airflow@postgres:5432/airflow
AIRFLOW_VAR__METADATA_DB_SCHEMA=airflow
# Setup heartbeat to check scheduler is alive
AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=10
